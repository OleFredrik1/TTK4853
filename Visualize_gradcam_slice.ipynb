{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "subject-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib.animation as anim\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.gridspec as gridspec\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "from model.gradcam import GradCAMpp, load_vgg16, init_gcpp\n",
    "from model.preprocessing import transform_datapoint\n",
    "import visualization.contours as contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "premier-comparative",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour_mask(img):\n",
    "    img = np.array(img[0])\n",
    "    g_img = contours.rgb_to_grayscale(img[-1, :, :])\n",
    "    return contours.contour_matrix_mask(g_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fallen-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../trained_model.pt'\n",
    "\n",
    "sample_filename1 = '../brain350/BraTS20_Training_350_flair.nii'\n",
    "sample_filename_mask = '../brain350/BraTS20_Training_350_seg.nii'\n",
    "sample_filename2 = '../brain350/BraTS20_Training_350_t1.nii'\n",
    "sample_filename3 = '../brain350/BraTS20_Training_350_t2.nii'\n",
    "sample_filename4 = '../brain350/BraTS20_Training_350_t1ce.nii'\n",
    "\n",
    "mean_path = 'data/mean.npy'\n",
    "std_path = 'data/std.npy'\n",
    "\n",
    "slice = 80 #Selecting what slice that we want to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "above-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "\n",
    "sample_img1 = nib.load(sample_filename1)\n",
    "sample_img1 = np.asanyarray(sample_img1.dataobj)\n",
    "\n",
    "sample_img2 = nib.load(sample_filename2)\n",
    "sample_img2 = np.asanyarray(sample_img2.dataobj)\n",
    "\n",
    "sample_img3 = nib.load(sample_filename3)\n",
    "sample_img3 = np.asanyarray(sample_img3.dataobj)\n",
    "\n",
    "sample_img4 = nib.load(sample_filename4)\n",
    "sample_img4 = np.asanyarray(sample_img4.dataobj)\n",
    "\n",
    "sample_mask = nib.load(sample_filename_mask)\n",
    "sample_mask = np.asanyarray(sample_mask.dataobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "greenhouse-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model and GradCam++\n",
    "vgg = load_vgg16(model_path)\n",
    "gcpp = init_gcpp(vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-determination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find GradCam++ mask\n",
    "image = np.array([sample_img1, sample_img2, sample_img3, sample_img4])\n",
    "image = np.swapaxes(image, 0, 3)\n",
    "\n",
    "mean = np.load(mean_path)\n",
    "std = np.load(std_path)\n",
    "\n",
    "image = image[slice, :, :, :] # Choose the slice we want\n",
    "\n",
    "image = transform_datapoint(image, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-serbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the parts outside the brain\n",
    "c_mask = contour_mask(image)\n",
    "\n",
    "gcpp_mask, _ = gcpp(image)\n",
    "gcpp_mask = gcpp_mask.numpy() * c_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "listed-recorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcpp_mask = F.upsample(torch.Tensor(gcpp_mask), size = (240, 240), mode = 'bilinear', align_corners = False)\n",
    "gcpp_mask = gcpp_mask[0, 0, :].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "electoral-orlando",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotate images for plotting\n",
    "sample_img1 = np.rot90(sample_img1)\n",
    "sample_img2 = np.rot90(sample_img2)\n",
    "sample_img3 = np.rot90(sample_img3)\n",
    "sample_img4 = np.rot90(sample_img4)\n",
    "sample_mask = np.rot90(sample_mask)\n",
    "gcpp_mask = np.rot90(gcpp_mask)\n",
    "\n",
    "#Dividing into the different labels\n",
    "mask_NCR_NET = sample_mask.copy()\n",
    "mask_NCR_NET[mask_NCR_NET == 1] = 1\n",
    "mask_NCR_NET[mask_NCR_NET == 2] = 0\n",
    "mask_NCR_NET[mask_NCR_NET == 4] = 0\n",
    "\n",
    "mask_ED = sample_mask.copy()\n",
    "mask_ED[mask_ED == 1] = 0\n",
    "mask_ED[mask_ED == 2] = 1\n",
    "mask_ED[mask_ED == 4] = 0\n",
    "\n",
    "mask_ET = sample_mask.copy()\n",
    "mask_ET[mask_ET == 1] = 0\n",
    "mask_ET[mask_ET == 2] = 0\n",
    "mask_ET[mask_ET == 4] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "frank-patrick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "gs = gridspec.GridSpec(nrows=2, ncols=4, height_ratios=[1, 1.5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "simple-malawi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, -0.1, '')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##  Varying density along a streamline\n",
    "#ax0 = fig.add_subplot(gs[0, 0])\n",
    "#flair = ax0.imshow(sample_img1[:,:,slice], cmap='bone')\n",
    "#ax0.set_title(\"FLAIR\", fontsize=18, weight='bold', y=-0.2)\n",
    "#fig.colorbar(flair)\n",
    "#\n",
    "##  Varying density along a streamline\n",
    "#ax1 = fig.add_subplot(gs[0, 1])\n",
    "#t1 = ax1.imshow(sample_img2[:,:,slice], cmap='bone')\n",
    "#ax1.set_title(\"T1\", fontsize=18, weight='bold', y=-0.2)\n",
    "#fig.colorbar(t1)\n",
    "#\n",
    "##  Varying density along a streamline\n",
    "#ax2 = fig.add_subplot(gs[0, 2])\n",
    "#t2 = ax2.imshow(sample_img3[:,:,slice], cmap='bone')\n",
    "#ax2.set_title(\"T2\", fontsize=18, weight='bold', y=-0.2)\n",
    "#fig.colorbar(t2)\n",
    "#\n",
    "##  Varying density along a streamline\n",
    "#ax3 = fig.add_subplot(gs[0, 3])\n",
    "#t1ce = ax3.imshow(sample_img4[:,:,slice], cmap='bone')\n",
    "#ax3.set_title(\"T1 contrast\", fontsize=18, weight='bold', y=-0.2)\n",
    "#fig.colorbar(t1ce)\n",
    "\n",
    "#  Varying density along a streamline\n",
    "ax4 = fig.add_subplot(gs[1, 1:3])\n",
    "\n",
    "l1 = ax4.imshow(sample_img1[:,:,slice], cmap='bone', alpha=1)\n",
    "l2 = ax4.imshow(np.ma.masked_where(mask_NCR_NET[:,:,slice] == False, mask_NCR_NET[:,:,slice]), cmap='spring', alpha = 1)\n",
    "l3 = ax4.imshow(np.ma.masked_where(mask_ED[:,:,slice]== False,  mask_ED[:,:,slice]), cmap='autumn', alpha=1)\n",
    "l4 = ax4.imshow(np.ma.masked_where(mask_ET[:,:,slice] == False, mask_ET[:,:,slice]), cmap='winter', alpha=1)\n",
    "l5 = ax4.imshow(np.ma.masked_where(gcpp_mask <= 0.001, gcpp_mask), cmap='Greens', alpha = 0.75)\n",
    "\n",
    "\n",
    "ax4.set_title(\"\", fontsize=20, weight='bold', y=-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "immediate-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = [ax.set_axis_off() for ax in [ax0,ax1,ax2,ax3, ax4]]\n",
    "\n",
    "#colors = [im.cmap(im.norm(1)) for im in [l1,l2, l3,l4]]\n",
    "colors = [im.cmap(im.norm(1)) for im in [l2, l3,l4]]\n",
    "colors.append(\"Green\")\n",
    "labels = ['Non-Enhancing tumor core', 'Peritumoral Edema ', 'GD-enhancing tumor', 'Grad-Cam++ prediction']\n",
    "patches = [ mpatches.Patch(color=colors[i], label=f\"{labels[i]}\") for i in range(len(labels))]\n",
    "# put those patched as legend-handles into the legend\n",
    "#fig.legend(handles=patches, loc='center right', borderaxespad = 0.5, bbox_to_anchor = (0.85, 0.35), fontsize = 'xx-large', title='Mask Labels', title_fontsize=18, edgecolor=\"black\",  facecolor='#c5c6c7')\n",
    "#fig.legend(handles=patches, bbox_to_anchor=(1.1, 0.65), loc=2, borderaxespad=0.4,fontsize = 'xx-large', title='Mask Labels', title_fontsize=18, edgecolor=\"black\",  facecolor='#c5c6c7')\n",
    "\n",
    "#fig.suptitle(\"Multimodal Scans -  Data | Manually-segmented mask - Target\", fontsize=20, weight='bold')\n",
    "\n",
    "fig.savefig(\"slice_with_gradcam_no_legend.png\", format=\"png\", pad_inches = 0.4, transparent=False, bbox_inches='tight')\n",
    "#fig.savefig(\"data_sample.png\", format=\"png\",  pad_inches=0.2, transparent=False, bbox_inches='tight')\n",
    "#fig.savefig(\"data_sample.svg\", format=\"svg\",  pad_inches=0.2, transparent=False, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-paper",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
